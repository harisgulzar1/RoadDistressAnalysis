{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "138RV844jidvWD65uvSawL5i7o7FZ8KdV",
      "authorship_tag": "ABX9TyPoTCdcJcmifzE5AGgtWuZS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harisgulzar1/RoadDistressAnalysis/blob/main/Lecture1_1_DistressAnalysisTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Road Distress Analysis\n",
        "## Lecture 1.1\n",
        "Introduction to Pytorch (Machine Learning Framework) and CNNs"
      ],
      "metadata": {
        "id": "8ClebroxIEhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Python Code\n",
        "The basic python code consists of following major parts.\n",
        "- Documentation (Optional)\n",
        "- Importing Libraries\n",
        "- Global Declaration\n",
        "- Defining a Class and its Functions\n",
        "- Subprogram Section (Functions)\n",
        "- Playground Section (Demonstration)"
      ],
      "metadata": {
        "id": "40Nmh-KFIlZD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3Mhj7EVKC8",
        "outputId": "c46d7c48-f060-411c-b0f7-e597f7c72c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Haris!\n",
            "Global variable: 10\n",
            "Addition result: 8\n",
            "Multiplication result: 24\n",
            "Square root of 16: 4.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Sample Python Script\n",
        "\n",
        "This script demonstrates various components of Python:\n",
        "- Documentation\n",
        "- Importing Libraries\n",
        "- Global Declaration\n",
        "- Defining a Class and its Functions\n",
        "- Subprogram Section (Functions)\n",
        "- Playground Section (Demonstration)\n",
        "\n",
        "Author: Haris Gulzar\n",
        "Date: June 2024\n",
        "\"\"\"\n",
        "\n",
        "# Importing libraries\n",
        "import math\n",
        "\n",
        "# Global variable declaration\n",
        "global_var = 10\n",
        "\n",
        "# Define a class\n",
        "class SampleClass:\n",
        "\n",
        "    # dafault function in each class\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def greet(self):\n",
        "        return f\"Hello, {self.name}!\"\n",
        "\n",
        "    def square_root(self, x):\n",
        "        return math.sqrt(x)\n",
        "\n",
        "# Subprogram section (functions)\n",
        "def add_numbers(a, b):\n",
        "    return a + b\n",
        "\n",
        "def multiply_numbers(a, b):\n",
        "    return a * b\n",
        "\n",
        "# Playground/Main section\n",
        "if __name__ == \"__main__\":\n",
        "    # Create an instance of SampleClass\n",
        "    obj = SampleClass(\"Haris\")\n",
        "\n",
        "    # Demonstrate class method\n",
        "    print(obj.greet())  # Output: Hello, Haris!\n",
        "\n",
        "    # Demonstrate global variable\n",
        "    print(f\"Global variable: {global_var}\")  # Output: Global variable: 10\n",
        "\n",
        "    # Demonstrate functions\n",
        "    print(f\"Addition result: {add_numbers(5, 3)}\")  # Output: Addition result: 8\n",
        "    print(f\"Multiplication result: {multiply_numbers(4, 6)}\")  # Output: Multiplication result: 24\n",
        "\n",
        "    # Demonstrate class method using imported math library\n",
        "    print(f\"Square root of 16: {obj.square_root(16)}\")  # Output: Square root of 16: 4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise ‚ùì\n",
        "Write a new function of division and use it in the main part of the code."
      ],
      "metadata": {
        "id": "EYWubroIJEZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Convolutional Network (CNN)"
      ],
      "metadata": {
        "id": "CJW_lEw6IHxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Prepare data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train set into train and validation set\n",
        "train_size = int(0.8 * len(mnist_train))\n",
        "val_size = len(mnist_train) - train_size\n",
        "mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(mnist_val, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(mnist_test, batch_size=64, shuffle=False)\n",
        "\n",
        "# Initialize the CNN model, loss function, and optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print statistics\n",
        "    epoch_loss = running_loss / len(mnist_train)\n",
        "    val_accuracy = correct / total * 100\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = test_correct / test_total * 100\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Etv729b2XCGk",
        "outputId": "3a09de83-074f-47eb-a622-46e7fbd593c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:00<00:00, 38098150.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 1110735.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 10965838.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 6519688.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.1789, Validation Accuracy: 97.71%\n",
            "Epoch [2/10], Loss: 0.0476, Validation Accuracy: 98.54%\n",
            "Epoch [3/10], Loss: 0.0332, Validation Accuracy: 98.66%\n",
            "Epoch [4/10], Loss: 0.0241, Validation Accuracy: 98.94%\n",
            "Epoch [5/10], Loss: 0.0173, Validation Accuracy: 98.88%\n",
            "Epoch [6/10], Loss: 0.0128, Validation Accuracy: 98.97%\n",
            "Epoch [7/10], Loss: 0.0107, Validation Accuracy: 99.02%\n",
            "Epoch [8/10], Loss: 0.0110, Validation Accuracy: 98.90%\n",
            "Epoch [9/10], Loss: 0.0084, Validation Accuracy: 98.72%\n",
            "Epoch [10/10], Loss: 0.0078, Validation Accuracy: 99.08%\n",
            "Finished Training\n",
            "Test Accuracy: 99.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Pretrained Model"
      ],
      "metadata": {
        "id": "kyulTEtuLJCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a path where you want to save the entire model\n",
        "model_path = '/content/drive/MyDrive/AItraining2data/mnist_cnn_model.pt'\n",
        "\n",
        "# Save the entire model (including architecture and state_dict) to the specified path\n",
        "torch.save(model, model_path)"
      ],
      "metadata": {
        "id": "AAR05TcsbvKg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing CNN with examples"
      ],
      "metadata": {
        "id": "xSodegg1LY2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "import random\n",
        "\n",
        "# Load the saved model from the .pt file\n",
        "model = torch.load(model_path)\n",
        "\n",
        "# Function to visualize and perform inference on a random MNIST sample\n",
        "def visualize_and_infer(model, dataset):\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Randomly pick a sample from the dataset\n",
        "    idx = random.randint(0, len(dataset) - 1)\n",
        "    image, label = dataset[idx]\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        # Forward pass through the model\n",
        "        output = model(image.unsqueeze(0))  # Add batch dimension\n",
        "\n",
        "        # Get predicted class\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    # Visualize the image and prediction\n",
        "    plt.imshow(image.squeeze(), cmap='gray')\n",
        "    plt.title(f'Label: {label}, Predicted: {predicted.item()}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Load MNIST dataset for inference\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "mnist_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Call the function to visualize and infer\n",
        "visualize_and_infer(model, mnist_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "goRaWy07Ydck",
        "outputId": "362b9006-7b33-46d1-db92-010841641cda"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise ‚ùì\n",
        "1. Draw an image on your PC\n",
        "2. Upload to the drive\n",
        "3. Predict using the following code"
      ],
      "metadata": {
        "id": "S-gAs1UjLe7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Function to preprocess the uploaded image\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Resize image to 28x28\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
        "        transforms.ToTensor(),  # Convert to tensor\n",
        "        transforms.Normalize((0.5,), (0.5,))  # Normalize\n",
        "    ])\n",
        "\n",
        "    # Apply transformations\n",
        "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    return image_tensor\n",
        "\n",
        "# Function to classify the uploaded image using the pre-trained model\n",
        "def classify_uploaded_image(model, image_path):\n",
        "    # Preprocess the image\n",
        "    image_tensor = preprocess_image(image_path)\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "    # Return predicted label\n",
        "    return predicted.item()\n",
        "\n",
        "# Example usage with an image from local PC\n",
        "image_path = '/content/4digit.png'\n",
        "\n",
        "# Replace with your local image path\n",
        "predicted_label = classify_uploaded_image(model, image_path)\n",
        "\n",
        "# Print the predicted label\n",
        "print(f'Predicted Label: {predicted_label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhMn_wT8eFV2",
        "outputId": "a482faf9-f2f5-413c-f2e3-af955ced1d83"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 7\n"
          ]
        }
      ]
    }
  ]
}